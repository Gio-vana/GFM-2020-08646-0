{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "import fix_yahoo_finance as yf\n",
    "import numpy as np\n",
    "from numpy import std\n",
    "from statistics import stdev\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import talib as tb\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM:\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.metrics import recall_score, f1_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# LSTM:\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Significado das entradas da função 'leitura': leitura padrão\n",
    "# diretorio: digitar entre aspas o diretório em que os dados históricos estão hospedados. Exemplo:'/home/giovana/Área de Trabalho/Implementações/Projeto/Dados/sITE/MGLU3.SA.csv'\n",
    "# Chamando a função:\n",
    "# leitura('/home/giovana/Área de Trabalho/Implementações/Projeto/Dados/sITE/MGLU3.SA.csv')\n",
    "\n",
    "def leitura(diretorio):\n",
    "    serie = pd.read_csv(diretorio)\n",
    "    return serie\n",
    "\n",
    "# Para visualizar um número especícico de linhas, defina uma variável como a função 'leitura' e aplique o método '.head()'\n",
    "# Exemplo:\n",
    "# >>> x = leitura('/home/giovana/Área de Trabalho/Implementações/Projeto/Dados/sITE/MGLU3.SA.csv')\n",
    "# >>> x.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Significado das entradas da função 'removendo_valores_discrepantes': remover as linhas que apresentem como valores '0', 'Nan' ou 'null'\n",
    "# dados_historicos: recomenda-se definir a função leitura como uma variável que pode ser interpretada como parâmetro. Um exemplo é a variável 'dados'.\n",
    "# Chamando a função:\n",
    "# removendo_volume_zerado(dados)\n",
    "\n",
    "def removendo_valores_discrepantes(dados_historicos):\n",
    "    dados_historicos = dados_historicos[dados_historicos['Volume']>0]\n",
    "    return dados_historicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removendo_dados_duplicados(dados_historicos):\n",
    "    dados_historicos = dados_historicos.drop_duplicates()\n",
    "    return dados_historicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remover_coluna_date(dados_historicos):\n",
    "    dados_sem_data = dados_historicos.drop(columns=['Date'])\n",
    "    return dados_sem_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gerando os indicadores técnicos\n",
    "\n",
    "- __Médias móveis:__ suaviza os preços anteriores para identificar a movimentação dos preços.\n",
    "    - Média móvel(simples e exponencial).\n",
    "- __Tendência:__ indica pontos de reversão de tendência.\n",
    "    - MACD.\n",
    "- __Momento:__ acompanha a taxa de variação dos preços.\n",
    "    - IFR.\n",
    "- __Volatilidade:__ identifica se as variações de preço futuras estão seguindo o mesmo ritmo das variações passadas.\n",
    "    - Bandas de Bollinger.\n",
    "- __Volume:__ determina se a tendência é relevante.\n",
    "    - Osciladores de Chaikin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MMS(dados_historicos, periodo):\n",
    "    #Criando uma janela dos elementos considerados:\n",
    "    janela = dados_historicos['Close'].rolling(window= periodo, center = True)#Decidir se será centrado\n",
    "    #Calculando a média da janela:\n",
    "    media_movel = janela.mean()\n",
    "    dados_historicos['MMS'] = media_movel\n",
    "    \n",
    "    #Problema do Nan:\n",
    "    dados_historicos['MMS'].values[:int(periodo/2)+1]= dados_historicos['MMS'].values[int(periodo/2)+1]\n",
    "    dados_historicos['MMS'].values[-(int(periodo/2)-1):]= dados_historicos['MMS'].values[-(int(periodo/2))]\n",
    "    \n",
    "    #Classificando a média móvel simples:\n",
    "    dif = dados_historicos['MMS'].values[1:]-dados_historicos['MMS'].values[:-1]\n",
    "    dif = np.concatenate([[np.nan], dif])\n",
    "    dados_historicos['DIF_MMS']= dif\n",
    "    dados_historicos['ClasseMMS']= (dados_historicos['DIF_MMS']>0).astype(int)\n",
    "    dados_historicos['ClasseMMS'].values[:1] = 0\n",
    "    return dados_historicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MME(dados_historicos, periodo, inicio_do_cálculo):\n",
    "    mme = dados_historicos['Close'].ewm(span = periodo, min_periods = inicio_do_cálculo, adjust = True).mean()\n",
    "    dados_historicos['MME'] = mme\n",
    "    \n",
    "    #Problema do Nan:\n",
    "    dados_historicos['MME'].values[:inicio_do_cálculo-1]= dados_historicos['MME'].values[inicio_do_cálculo-1]\n",
    "    \n",
    "    #Classificando a média móvel exponencial:\n",
    "    dif_1 = dados_historicos['MME'].values[1:]-dados_historicos['MME'].values[:-1]\n",
    "    dif_1 = np.concatenate([[np.nan], dif_1])\n",
    "    dados_historicos['DIF_MME']= dif_1\n",
    "    dados_historicos['ClasseMME']= (dados_historicos['DIF_MME']>0).astype(int)\n",
    "    dados_historicos['ClasseMME'].values[:1] = 0\n",
    "    return dados_historicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MACD (dados_historicos):\n",
    "    #parâmetros da linha macd\n",
    "    mme26 = dados_historicos['Close'].ewm(span = 26, min_periods = 0, adjust = True).mean()\n",
    "    dados_historicos['MME26']=mme26\n",
    "    mme12 = dados_historicos['Close'].ewm(span = 12, min_periods = 0, adjust = True).mean()\n",
    "    dados_historicos['MME12']=mme12\n",
    "    #linha macd\n",
    "    macd = dados_historicos['MME12'] - dados_historicos['MME26']\n",
    "    dados_historicos['MACD'] = macd\n",
    "    \n",
    "    #linha de sinal: mme(9)\n",
    "    #mme9 = dados_historicos['Close'].ewm(span = 9, min_periods = 0, adjust = True).mean()\n",
    "    #dados_historicos['MME9']=mme9\n",
    "    \n",
    "    #Classificando o macd:\n",
    "    dados_historicos['ClasseMACD'] = (dados_historicos['MACD']>0).astype(int)\n",
    "    return dados_historicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O padrão é utilizar 14 dias, mas também se usa 9 ou 25. \n",
    "\n",
    "def RSI(dados_historicos, periodo):\n",
    "    dados_historicos['RSI'] = tb.RSI(dados_historicos['Close'] , periodo)\n",
    "    \n",
    "    #Classificação:\n",
    "    dados_historicos['ClasseRSI']=1\n",
    "    dados_historicos.loc[dados_historicos['RSI']<50,'ClasseRSI']=0\n",
    "    \n",
    "    #Problema do Nan:\n",
    "    dados_historicos['RSI'].values[:periodo]= dados_historicos['RSI'].values[periodo]\n",
    "    \n",
    "    return dados_historicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target(dados_historicos):\n",
    "    soma = dados_historicos['ClasseMMS']+dados_historicos['ClasseMME']+dados_historicos['ClasseMACD']+dados_historicos['ClasseRSI']\n",
    "    dados_historicos['soma'] = soma\n",
    "    dados_historicos['Soma'] = (dados_historicos['soma']>2).astype(int)\n",
    "    return dados_historicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_treinamento(dados_historicos):\n",
    "    soma = dados_historicos['ClasseMMS']+dados_historicos['ClasseMME']+dados_historicos['ClasseMACD']+dados_historicos['ClasseRSI']\n",
    "    dados_historicos['soma'] = soma\n",
    "    dados_historicos['Soma'] = (dados_historicos['soma']>2).astype(int)\n",
    "    classe = pd.DataFrame()\n",
    "    classe['target'] = dados_historicos['Soma'].values[:int(len(dados_historicos)*0.7)+1]\n",
    "    return classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  conjunto_indicadores_treinamento(dados_historicos):\n",
    "    classe = pd.DataFrame()\n",
    "    classe['MMS'] = dados_historicos['MMS'].values[:int(len(dados_historicos)*0.7)+1]\n",
    "    classe['MME'] = dados_historicos['MME'].values[:int(len(dados_historicos)*0.7)+1]\n",
    "    classe['MACD'] = dados_historicos['MACD'].values[:int(len(dados_historicos)*0.7)+1]\n",
    "    classe['RSI'] = dados_historicos['RSI'].values[:int(len(dados_historicos)*0.7)+1]\n",
    "    return classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  conjunto_indicadores_teste(dados_historicos):\n",
    "    classe_teste = pd.DataFrame()\n",
    "    classe_teste['MMS'] = dados_historicos['MMS'].values[1+int(len(dados_historicos)*0.7):]\n",
    "    classe_teste['MME'] = dados_historicos['MME'].values[1+int(len(dados_historicos)*0.7):]\n",
    "    classe_teste['MACD'] = dados_historicos['MACD'].values[1+int(len(dados_historicos)*0.7):]\n",
    "    classe_teste['RSI'] = dados_historicos['RSI'].values[1+int(len(dados_historicos)*0.7):]\n",
    "    return classe_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_teste(dados_historicos):\n",
    "    soma = dados_historicos['ClasseMMS']+dados_historicos['ClasseMME']+dados_historicos['ClasseMACD']+dados_historicos['ClasseRSI']\n",
    "    dados_historicos['soma'] = soma\n",
    "    dados_historicos['Soma'] = (dados_historicos['soma']>2).astype(int)\n",
    "    classe = pd.DataFrame()\n",
    "    classe['target'] = dados_historicos['Soma'].values[int(len(dados_historicos)*0.7)+1:]\n",
    "    return classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizador(indicadores):\n",
    "    indicadores = MinMaxScaler(feature_range=(0,1)).fit_transform(indicadores)\n",
    "    return indicadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelo(C, kernel, gamma, vetor_caracteristica_treinamento, rotulo_treinamento, vetor_caracteristica_teste):\n",
    "    model = svm.SVC(C = C, kernel= kernel, gamma= gamma) \n",
    "    model.fit(vetor_caracteristica_treinamento, rotulo_treinamento)\n",
    "    predicted= model.predict(vetor_caracteristica_teste)\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_target(target):\n",
    "    target_reshape = target.reshape(len(target), )\n",
    "    return target_reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A acurácia (A) corresponde à taxa de acertos do modelo e relaciona o total de entradas previdas corretamente com o total de previsões\n",
    "\n",
    "$$\n",
    "A = \\frac{t_p + t_n}{t_p + t_n + f_p + f_n}\n",
    "$$\n",
    "\n",
    "\n",
    "A precisão (P) corresponde à taxa de acerto de previsões positivas e relaciona os verdadeiros positivos com o total de positivos previstos\n",
    "\n",
    "$$P = \\frac{t_p}{t_p + f_p}$$\n",
    "\n",
    "\n",
    "A métrica recall (R) indica o número de valores previstos corretamente dentro de uma classe relacionando o número de previsões corretas em uma classe e o número total de ocorrências dela e, portanto, pode ser calculado para ambas as classes\n",
    "$$R =\\frac{t_p}{t_p + f_n}$$\n",
    "\n",
    "A F1-score representa a média harmônica entre as medidas de precisão e recall\n",
    "$$F1 = \\frac{2RP}{P + R}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relatorio(previsao_do_modelo, target_teste):\n",
    "    matriz_confusão = confusion_matrix(previsao_do_modelo,target_teste)\n",
    "    \n",
    "    \n",
    "    rel = pd.DataFrame()\n",
    "    rel['Falsos positivo - fp'] = [matriz_confusão[0,1]]\n",
    "    rel['Verdadeiros positivo - tp'] = [matriz_confusão[1,1]]\n",
    "    rel['Falsos negativo - fn'] = [matriz_confusão[1,0]]\n",
    "    rel['Verdadeiros negativo  - tn'] = [matriz_confusão[0,0]]\n",
    "    rel['Recall'] = [recall_score(target_teste, previsao_do_modelo)]\n",
    "    rel['F1-score'] = [f1_score(target_teste, previsao_do_modelo)]\n",
    "    rel['Precisão'] = [precision_score(target_teste, previsao_do_modelo)]\n",
    "    rel['Acurácia'] = [accuracy_score(target_teste, previsao_do_modelo)]\n",
    "    return rel\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV \n",
    "\n",
    " O GridSearchCV pega um dicionário que descreve os parâmetros que podem ser experimentados em um modelo para treiná-lo. A grade de parâmetros é definida como um dicionário, onde as chaves são os parâmetros e os valores são as configurações a serem testadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_grid(x_treinamento, x_teste, y_treinamento, y_teste):\n",
    "    # Definindo os parâmetros:\n",
    "    parametros_grid = {'C':  [0.1,1, 10, 100], \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel': ['rbf', 'poly', 'linear', 'sigmoid']} \n",
    "    # Criando o modelo em que a grade de parâmetros será testada:\n",
    "    grid = GridSearchCV(SVC(), parametros_grid, refit = True, verbose = 3)\n",
    "    # Treinando o modelo:\n",
    "    grid.fit(x_treinamento, y_treinamento)\n",
    "    # Imprimindo os melhores parâmetros:\n",
    "    print('Melhores parâmetros')\n",
    "    print(grid.best_params_)\n",
    "    # Imprimindo as configurações do melhor estimador:\n",
    "    print('Melhor estimador')\n",
    "    print(grid.best_estimator_)\n",
    "    # Realizando as predições:\n",
    "    grid_predictions = grid.predict(x_teste)\n",
    "    # Imprimindo as métricas de avaliação:\n",
    "    print(classification_report(y_teste, grid_predictions))\n",
    "    \n",
    "    \n",
    "    \n",
    "    matriz_confusão = confusion_matrix(grid_predictions,y_teste)\n",
    "    print(f'Falsos positivo - fp: {matriz_confusão[0,1]}')\n",
    "    print(f'Verdadeiros positivo - tp: {matriz_confusão[1,1]}')\n",
    "    print(f'Falsos negativo - fn: {matriz_confusão[1,0]}')\n",
    "    print(f'Verdadeiros negativo  - tn: {matriz_confusão[0,0]}')\n",
    "    print(f'Recall: {recall_score(y_teste, grid_predictions)}')\n",
    "    print(f'F1-score: {f1_score(y_teste, grid_predictions)}')\n",
    "    print(f'Precisão: {precision_score(y_teste, grid_predictions)}')\n",
    "    print(f'Acurácia: {accuracy_score(y_teste, grid_predictions)}')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm1(indicadores_treinamento, indicadores_teste, target_treinamento, target_teste):\n",
    "    \n",
    "    # Arrumando a entrada do conjunto de treinamento no formato exigido pelo LSTM\n",
    "    xtreino = indicadores_treinamento\n",
    "    xtreino_novo = xtreino.reshape((xtreino.shape[0],xtreino.shape[1],1))\n",
    "    \n",
    "    # Arrumando a entrada do conjunto de teste no formato exigido pelo LSTM\n",
    "    xteste = indicadores_teste\n",
    "    xteste_novo = xteste.reshape((xteste.shape[0],xteste.shape[1],1))\n",
    "    \n",
    "    # Modelo 1:\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, activation= 'relu', input_shape = (xtreino_novo.shape[1],xtreino_novo.shape[2])))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Resumo da Rede Neural:\n",
    "    print('Resumo da Rede Neural:')\n",
    "    model.summary()\n",
    "    print('---------------------------------------------')\n",
    "    \n",
    "    # Ajuste da Rede Neural ao conjunto de treinamento:\n",
    "    model.fit(xtreino_novo, target_treinamento, epochs = 10, batch_size = 1)\n",
    "    \n",
    "    # Ajustando o modelo ao conjunto de entrada de treinamento:\n",
    "    yajustadolstm = model.predict_classes(xtreino_novo)\n",
    "    # Avaliando a previsão:\n",
    "    print('---------------------------------------------')\n",
    "    print('Ajustando o modelo ao conjunto de entrada de treinamento')\n",
    "    matriz_confusão = confusion_matrix(yajustadolstm,target_treinamento)\n",
    "    print(f'Falsos positivo - fp: {matriz_confusão[0,1]}')\n",
    "    print(f'Verdadeiros positivo - tp: {matriz_confusão[1,1]}')\n",
    "    print(f'Falsos negativo - fn: {matriz_confusão[1,0]}')\n",
    "    print(f'Verdadeiros negativo  - tn: {matriz_confusão[0,0]}')\n",
    "    print(f'Recall: {recall_score(target_treinamento, yajustadolstm)}')\n",
    "    print(f'F1-score: {f1_score(target_treinamento, yajustadolstm)}')\n",
    "    print(f'Precisão: {precision_score(target_treinamento, yajustadolstm)}')\n",
    "    print(f'Acurácia: {accuracy_score(target_treinamento, yajustadolstm)}')\n",
    "    \n",
    "    # Ajustando o modelo ao conjunto de entrada de teste: \n",
    "    y_predict = model.predict_classes(xteste_novo)\n",
    "    # Avaliando a previsão:\n",
    "    print('---------------------------------------------')\n",
    "    print('Ajustando o modelo ao conjunto de entrada de teste')\n",
    "    matriz_confusão = confusion_matrix(y_predict,target_teste)\n",
    "    print(f'Falsos positivo - fp: {matriz_confusão[0,1]}')\n",
    "    print(f'Verdadeiros positivo - tp: {matriz_confusão[1,1]}')\n",
    "    print(f'Falsos negativo - fn: {matriz_confusão[1,0]}')\n",
    "    print(f'Verdadeiros negativo  - tn: {matriz_confusão[0,0]}')\n",
    "    print(f'Recall: {recall_score(target_teste, y_predict)}')\n",
    "    print(f'F1-score: {f1_score(target_teste, y_predict)}')\n",
    "    print(f'Precisão: {precision_score(target_teste, y_predict)}')\n",
    "    print(f'Acurácia: {accuracy_score(target_teste, y_predict)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm2(indicadores_treinamento, indicadores_teste, target_treinamento, target_teste):\n",
    "    \n",
    "    # Arrumando a entrada do conjunto de treinamento no formato exigido pelo LSTM\n",
    "    xtreino = indicadores_treinamento\n",
    "    xtreino_novo = xtreino.reshape((xtreino.shape[0],xtreino.shape[1],1))\n",
    "    \n",
    "    # Arrumando a entrada do conjunto de teste no formato exigido pelo LSTM\n",
    "    xteste = indicadores_teste\n",
    "    xteste_novo = xteste.reshape((xteste.shape[0],xteste.shape[1],1))\n",
    "    \n",
    "    # Modelo 2:\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(10, activation= 'relu', return_sequences = True, input_shape = (xtreino_novo.shape[1],xtreino_novo.shape[2])))\n",
    "    model.add(LSTM(10, activation= 'relu', return_sequences = True))\n",
    "    model.add(LSTM(10, activation= 'relu', return_sequences = True))\n",
    "    model.add(LSTM(10, activation= 'relu', return_sequences = True))\n",
    "    model.add(LSTM(10, activation= 'relu'))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Resumo da Rede Neural:\n",
    "    print('Resumo da Rede Neural:')\n",
    "    model.summary()\n",
    "    print('---------------------------------------------')\n",
    "    \n",
    "    # Ajuste da Rede Neural ao conjunto de treinamento:\n",
    "    model.fit(xtreino_novo, target_treinamento, epochs = 10, batch_size = 1)\n",
    "    \n",
    "    # Ajustando o modelo ao conjunto de entrada de treinamento:\n",
    "    yajustadolstm = model.predict_classes(xtreino_novo)\n",
    "    # Avaliando a previsão:\n",
    "    print('---------------------------------------------')\n",
    "    print('Ajustando o modelo ao conjunto de entrada de treinamento')\n",
    "    matriz_confusão = confusion_matrix(yajustadolstm,target_treinamento)\n",
    "    print(f'Falsos positivo - fp: {matriz_confusão[0,1]}')\n",
    "    print(f'Verdadeiros positivo - tp: {matriz_confusão[1,1]}')\n",
    "    print(f'Falsos negativo - fn: {matriz_confusão[1,0]}')\n",
    "    print(f'Verdadeiros negativo  - tn: {matriz_confusão[0,0]}')\n",
    "    print(f'Recall: {recall_score(target_treinamento, yajustadolstm)}')\n",
    "    print(f'F1-score: {f1_score(target_treinamento, yajustadolstm)}')\n",
    "    print(f'Precisão: {precision_score(target_treinamento, yajustadolstm)}')\n",
    "    print(f'Acurácia: {accuracy_score(target_treinamento, yajustadolstm)}')\n",
    "    \n",
    "    # Ajustando o modelo ao conjunto de entrada de teste: \n",
    "    y_predict = model.predict_classes(xteste_novo)\n",
    "    # Avaliando a previsão:\n",
    "    print('---------------------------------------------')\n",
    "    print('Ajustando o modelo ao conjunto de entrada de teste')\n",
    "    matriz_confusão = confusion_matrix(y_predict,target_teste)\n",
    "    print(f'Falsos positivo - fp: {matriz_confusão[0,1]}')\n",
    "    print(f'Verdadeiros positivo - tp: {matriz_confusão[1,1]}')\n",
    "    print(f'Falsos negativo - fn: {matriz_confusão[1,0]}')\n",
    "    print(f'Verdadeiros negativo  - tn: {matriz_confusão[0,0]}')\n",
    "    print(f'Recall: {recall_score(target_teste, y_predict)}')\n",
    "    print(f'F1-score: {f1_score(target_teste, y_predict)}')\n",
    "    print(f'Precisão: {precision_score(target_teste, y_predict)}')\n",
    "    print(f'Acurácia: {accuracy_score(target_teste, y_predict)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm3(indicadores_treinamento, indicadores_teste, target_treinamento, target_teste):\n",
    "    \n",
    "    # Arrumando a entrada do conjunto de treinamento no formato exigido pelo LSTM\n",
    "    xtreino = indicadores_treinamento\n",
    "    xtreino_novo = xtreino.reshape((xtreino.shape[0],xtreino.shape[1],1))\n",
    "    \n",
    "    # Arrumando a entrada do conjunto de teste no formato exigido pelo LSTM\n",
    "    xteste = indicadores_teste\n",
    "    xteste_novo = xteste.reshape((xteste.shape[0],xteste.shape[1],1))\n",
    "    \n",
    "    # Modelo 3:\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(12, activation='relu', return_sequences = True, input_shape = (xtreino_novo.shape[1],xtreino_novo.shape[2])))\n",
    "    model.add(LSTM(8, activation='relu'))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Resumo da Rede Neural:\n",
    "    print('Resumo da Rede Neural:')\n",
    "    model.summary()\n",
    "    print('---------------------------------------------')\n",
    "    \n",
    "    # Ajuste da Rede Neural ao conjunto de treinamento:\n",
    "    model.fit(xtreino_novo, target_treinamento, epochs = 10, batch_size = 1)\n",
    "    \n",
    "    # Ajustando o modelo ao conjunto de entrada de treinamento:\n",
    "    yajustadolstm = model.predict_classes(xtreino_novo)\n",
    "    # Avaliando a previsão:\n",
    "    print('---------------------------------------------')\n",
    "    print('Ajustando o modelo ao conjunto de entrada de treinamento')\n",
    "    matriz_confusão = confusion_matrix(yajustadolstm,target_treinamento)\n",
    "    print(f'Falsos positivo - fp: {matriz_confusão[0,1]}')\n",
    "    print(f'Verdadeiros positivo - tp: {matriz_confusão[1,1]}')\n",
    "    print(f'Falsos negativo - fn: {matriz_confusão[1,0]}')\n",
    "    print(f'Verdadeiros negativo  - tn: {matriz_confusão[0,0]}')\n",
    "    print(f'Recall: {recall_score(target_treinamento, yajustadolstm)}')\n",
    "    print(f'F1-score: {f1_score(target_treinamento, yajustadolstm)}')\n",
    "    print(f'Precisão: {precision_score(target_treinamento, yajustadolstm)}')\n",
    "    print(f'Acurácia: {accuracy_score(target_treinamento, yajustadolstm)}')\n",
    "    \n",
    "    # Ajustando o modelo ao conjunto de entrada de teste: \n",
    "    y_predict = model.predict_classes(xteste_novo)\n",
    "    # Avaliando a previsão:\n",
    "    print('---------------------------------------------')\n",
    "    print('Ajustando o modelo ao conjunto de entrada de teste')\n",
    "    matriz_confusão = confusion_matrix(y_predict,target_teste)\n",
    "    print(f'Falsos positivo - fp: {matriz_confusão[0,1]}')\n",
    "    print(f'Verdadeiros positivo - tp: {matriz_confusão[1,1]}')\n",
    "    print(f'Falsos negativo - fn: {matriz_confusão[1,0]}')\n",
    "    print(f'Verdadeiros negativo  - tn: {matriz_confusão[0,0]}')\n",
    "    print(f'Recall: {recall_score(target_teste, y_predict)}')\n",
    "    print(f'F1-score: {f1_score(target_teste, y_predict)}')\n",
    "    print(f'Precisão: {precision_score(target_teste, y_predict)}')\n",
    "    print(f'Acurácia: {accuracy_score(target_teste, y_predict)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm4(indicadores_treinamento, indicadores_teste, target_treinamento, target_teste):\n",
    "    \n",
    "    # Arrumando a entrada do conjunto de treinamento no formato exigido pelo LSTM\n",
    "    xtreino = indicadores_treinamento\n",
    "    xtreino_novo = xtreino.reshape((xtreino.shape[0],xtreino.shape[1],1))\n",
    "    \n",
    "    # Arrumando a entrada do conjunto de teste no formato exigido pelo LSTM\n",
    "    xteste = indicadores_teste\n",
    "    xteste_novo = xteste.reshape((xteste.shape[0],xteste.shape[1],1))\n",
    "    \n",
    "    # Modelo 4:\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(30, activation= 'relu', input_shape = (xtreino_novo.shape[1],xtreino_novo.shape[2])))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Resumo da Rede Neural:\n",
    "    print('Resumo da Rede Neural:')\n",
    "    model.summary()\n",
    "    print('---------------------------------------------')\n",
    "    \n",
    "    # Ajuste da Rede Neural ao conjunto de treinamento:\n",
    "    model.fit(xtreino_novo, target_treinamento, epochs = 10, batch_size = 1)\n",
    "    \n",
    "    # Ajustando o modelo ao conjunto de entrada de treinamento:\n",
    "    yajustadolstm = model.predict_classes(xtreino_novo)\n",
    "    # Avaliando a previsão:\n",
    "    print('---------------------------------------------')\n",
    "    print('Ajustando o modelo ao conjunto de entrada de treinamento')\n",
    "    matriz_confusão = confusion_matrix(yajustadolstm,target_treinamento)\n",
    "    print(f'Falsos positivo - fp: {matriz_confusão[0,1]}')\n",
    "    print(f'Verdadeiros positivo - tp: {matriz_confusão[1,1]}')\n",
    "    print(f'Falsos negativo - fn: {matriz_confusão[1,0]}')\n",
    "    print(f'Verdadeiros negativo  - tn: {matriz_confusão[0,0]}')\n",
    "    print(f'Recall: {recall_score(target_treinamento, yajustadolstm)}')\n",
    "    print(f'F1-score: {f1_score(target_treinamento, yajustadolstm)}')\n",
    "    print(f'Precisão: {precision_score(target_treinamento, yajustadolstm)}')\n",
    "    print(f'Acurácia: {accuracy_score(target_treinamento, yajustadolstm)}')\n",
    "    \n",
    "    # Ajustando o modelo ao conjunto de entrada de teste: \n",
    "    y_predict = model.predict_classes(xteste_novo)\n",
    "    # Avaliando a previsão:\n",
    "    print('---------------------------------------------')\n",
    "    print('Ajustando o modelo ao conjunto de entrada de teste')\n",
    "    matriz_confusão = confusion_matrix(y_predict,target_teste)\n",
    "    print(f'Falsos positivo - fp: {matriz_confusão[0,1]}')\n",
    "    print(f'Verdadeiros positivo - tp: {matriz_confusão[1,1]}')\n",
    "    print(f'Falsos negativo - fn: {matriz_confusão[1,0]}')\n",
    "    print(f'Verdadeiros negativo  - tn: {matriz_confusão[0,0]}')\n",
    "    print(f'Recall: {recall_score(target_teste, y_predict)}')\n",
    "    print(f'F1-score: {f1_score(target_teste, y_predict)}')\n",
    "    print(f'Precisão: {precision_score(target_teste, y_predict)}')\n",
    "    print(f'Acurácia: {accuracy_score(target_teste, y_predict)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

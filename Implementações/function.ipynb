{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1><center>Implementações</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leitura da Base de Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Importando as bibliotecas utilizadas na tarefa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo a função que realizará a leitura da base de dados disponíveis no diretório"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leitura(diretorio):\n",
    "    serie = pd.read_csv(diretorio)\n",
    "    return serie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-processamento de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removendo_valores_discrepantes(dados_historicos):\n",
    "    dados_historicos = dados_historicos[dados_historicos['Volume']>0]\n",
    "    return dados_historicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removendo_dados_duplicados(dados_historicos):\n",
    "    dados_historicos = dados_historicos.drop_duplicates()\n",
    "    return dados_historicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remover_coluna_date(dados_historicos):\n",
    "    dados_sem_data = dados_historicos.drop(columns=['Date'])\n",
    "    return dados_sem_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gerando os indicadores técnicos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Importando as bibliotecas utilizadas na tarefa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talib as tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo a função que retornará os indicadores técnicos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indicador baseado em médias móveis: suavização de preços anteriores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MMS(dados_historicos, periodo):\n",
    "    \n",
    "    # Média Móvel Simples:\n",
    "    dados_historicos['MMS'] = tb.SMA(dados_historicos['Close'], timeperiod= periodo)\n",
    "\n",
    "    ##Problema do Nan:\n",
    "    dados_historicos['MMS'].values[:int(periodo)-1]= dados_historicos['MMS'].values[int(periodo)-1]\n",
    "    \n",
    "    ##Classificação:\n",
    "    dif = dados_historicos['MMS'].values[1:]-dados_historicos['MMS'].values[:-1]\n",
    "    dif = np.concatenate([[np.nan], dif])\n",
    "    dados_historicos['DIF_MMS']= dif\n",
    "    dados_historicos['ClasseMMS']= (dados_historicos['DIF_MMS']>0).astype(int)\n",
    "    dados_historicos['ClasseMMS'].values[:1] = 0\n",
    "    \n",
    "    \n",
    "    return dados_historicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MME(dados_historicos, periodo):\n",
    "    \n",
    "    \n",
    "    # Média Móvel Exponencial:\n",
    "    dados_historicos['MME'] = tb.EMA(dados_historicos['Close'], timeperiod= periodo)\n",
    "\n",
    "    ##Problema do Nan:\n",
    "    dados_historicos['MME'].values[:int(periodo)-1]= dados_historicos['MME'].values[int(periodo)-1]\n",
    "    \n",
    "    ##Classificação:\n",
    "    \n",
    "    dif_1 = dados_historicos['MME'].values[1:]-dados_historicos['MME'].values[:-1]\n",
    "    dif_1 = np.concatenate([[np.nan], dif_1])\n",
    "    dados_historicos['DIF_MME']= dif_1\n",
    "    dados_historicos['ClasseMME']= (dados_historicos['DIF_MME']>0).astype(int)\n",
    "    dados_historicos['ClasseMME'].values[:1] = 0\n",
    "    return dados_historicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MACD (dados_historicos):\n",
    "    # MACD:\n",
    "    dados_historicos['MACD'], dados_historicos['sinal_MACD'], dados_historicos['macdhist'] = tb.MACD(dados_historicos['Close'], fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "    ##Problema do Nan:\n",
    "    dados_historicos['MACD'].values[:33]= dados_historicos['MACD'].values[33]\n",
    "    dados_historicos['sinal_MACD'].values[:33]= dados_historicos['sinal_MACD'].values[33]\n",
    "    dados_historicos['macdhist'].values[:33]= dados_historicos['macdhist'].values[33]\n",
    "    ##Classificando o macd:\n",
    "    dados_historicos['ClasseMACD']=0\n",
    "    dados_historicos.loc[dados_historicos['sinal_MACD']<dados_historicos['MACD'],'ClasseMACD']=1\n",
    "    return dados_historicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RSI(dados_historicos, periodo):\n",
    "    dados_historicos['RSI'] = tb.RSI(dados_historicos['Close'] , periodo)\n",
    "    \n",
    "    #Problema do Nan:\n",
    "    dados_historicos['RSI'].values[:periodo]= dados_historicos['RSI'].values[periodo]\n",
    "    \n",
    "    #Classificação:\n",
    "    dados_historicos['ClasseRSI']=1\n",
    "    dados_historicos.loc[dados_historicos['RSI']<50,'ClasseRSI']=0\n",
    "    \n",
    "    return dados_historicos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definindo os conjuntos de treinamento e teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Somente indicadores técnicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  conjunto_indicadores_treinamento(dados_historicos):\n",
    "    classe = pd.DataFrame()\n",
    "    classe = pd.DataFrame()\n",
    "    classe['MMS'] = dados_historicos['MMS'].values[:int(len(dados_historicos)*0.7)+1]\n",
    "    classe['MME'] = dados_historicos['MME'].values[:int(len(dados_historicos)*0.7)+1]\n",
    "    classe['MACD'] = dados_historicos['MACD'].values[:int(len(dados_historicos)*0.7)+1]\n",
    "    classe['RSI'] = dados_historicos['RSI'].values[:int(len(dados_historicos)*0.7)+1]\n",
    " \n",
    "    return classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  conjunto_indicadores_teste(dados_historicos):\n",
    "    classe_teste = pd.DataFrame()\n",
    "    classe_teste['MMS'] = dados_historicos['MMS'].values[1+int(len(dados_historicos)*0.7):]\n",
    "    classe_teste['MME'] = dados_historicos['MME'].values[1+int(len(dados_historicos)*0.7):]\n",
    "    classe_teste['MACD'] = dados_historicos['MACD'].values[1+int(len(dados_historicos)*0.7):]\n",
    "    classe_teste['RSI'] = dados_historicos['RSI'].values[1+int(len(dados_historicos)*0.7):]\n",
    "    return classe_teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotulação das amostras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_treinamento(dados_historicos):\n",
    "    soma = dados_historicos['ClasseMMS']+dados_historicos['ClasseMME']+dados_historicos['ClasseMACD']+dados_historicos['ClasseRSI']\n",
    "    dados_historicos['soma'] = soma\n",
    "    dados_historicos['Soma'] = (dados_historicos['soma']>2).astype(int)\n",
    "    classe = pd.DataFrame()\n",
    "    classe['target'] = dados_historicos['Soma'].values[:int(len(dados_historicos)*0.7)+1]\n",
    "    return classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_teste(dados_historicos):\n",
    "    soma = dados_historicos['ClasseMMS']+dados_historicos['ClasseMME']+dados_historicos['ClasseMACD']+dados_historicos['ClasseRSI']\n",
    "    dados_historicos['soma'] = soma\n",
    "    dados_historicos['Soma'] = (dados_historicos['soma']>2).astype(int)\n",
    "    classe = pd.DataFrame()\n",
    "    classe['target'] = dados_historicos['Soma'].values[int(len(dados_historicos)*0.7)+1:]\n",
    "    return classe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizando a base de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Importando as bibliotecas utilizadas na tarefa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Definindo a função que normalizará  a base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizador(indicadores):\n",
    "    indicadores = MinMaxScaler(feature_range=(0,1)).fit_transform(indicadores)\n",
    "    return indicadores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adequando o formato do conjunto de rótulos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Importando as bibliotecas utilizadas na tarefa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo a função responsável por redimensionar o conjunto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_target(target):\n",
    "    target_reshape = target.reshape(len(target), )\n",
    "    return target_reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliando os modelos criados na sequência"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando as bibliotecas utilizadas na tarefa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.metrics import recall_score, f1_score, precision_score\n",
    "from sklearn.metrics import roc_curve, plot_roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo a  função responsável por executar a tarefa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relatorio(previsao_do_modelo, target, proba, nome_fig, nome_mtz):\n",
    "    matriz_confusão = confusion_matrix(target, previsao_do_modelo)\n",
    "    print(f'Falsos positivo - fp: {matriz_confusão[0,1]}')\n",
    "    print(f'Verdadeiros positivo - tp: {matriz_confusão[1,1]}')\n",
    "    print(f'Falsos negativo - fn: {matriz_confusão[1,0]}')\n",
    "    print(f'Verdadeiros negativo  - tn: {matriz_confusão[0,0]}')\n",
    "    print(f'Recall: {round(recall_score(target, previsao_do_modelo),2)}')\n",
    "    print(f'F1-score: {round(f1_score(target, previsao_do_modelo),2)}')\n",
    "    print(f'Precisão: {round(precision_score(target, previsao_do_modelo), 2)}')\n",
    "    print(f'Acurácia: {round(accuracy_score(target, previsao_do_modelo),2)}')\n",
    "    \n",
    "    print('---------------------------------------------')\n",
    "    \n",
    "    figura, eixo = plt.subplots(figsize=(6, 6))\n",
    "    eixo.matshow(matriz_confusão, cmap=plt.cm.Greens)\n",
    "    for i in range(matriz_confusão.shape[0]):\n",
    "        for j in range(matriz_confusão.shape[1]):\n",
    "            eixo.text(x=j, y=i,s=matriz_confusão[i, j], va='center', ha='center', size='xx-large')\n",
    " \n",
    "    plt.xlabel('Predição', fontsize=15)\n",
    "    plt.ylabel('Real', fontsize=15)\n",
    "    plt.title('Matriz de Confusão', fontsize=18)\n",
    "    plt.savefig(nome_mtz, dpi = 300)\n",
    "    \n",
    "    \n",
    "    print('---------------------------------------------')\n",
    "    \n",
    "    #taxa_fp, taxa_vp, limiar = roc_curve(target, previsao_do_modelo)\n",
    "    taxa_fp, taxa_vp, limiar = roc_curve(target, proba[:,1])\n",
    "    auc = roc_auc_score(target, proba[:,1])\n",
    "    \n",
    "\n",
    "    figure = plt.figure(figsize = (6, 6))\n",
    "    plt.plot(taxa_fp, taxa_vp, linewidth = 2, label='AUC = %0.2f' % auc)\n",
    "    plt.title('Curva ROC')\n",
    "    plt.plot([0, 1], [0, 1],'k--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('Taxa de verdadeiro positivo')\n",
    "    plt.xlabel('Taxa de falso positivo ')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(nome_fig, dpi = 300)\n",
    "    \n",
    "    return figura, figure\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relatorio_lstm(previsao_do_modelo, target, proba, nome_fig, nome_mtz):\n",
    "    matriz_confusão = confusion_matrix(target, previsao_do_modelo)\n",
    "    print(f'Falsos positivo - fp: {matriz_confusão[0,1]}')\n",
    "    print(f'Verdadeiros positivo - tp: {matriz_confusão[1,1]}')\n",
    "    print(f'Falsos negativo - fn: {matriz_confusão[1,0]}')\n",
    "    print(f'Verdadeiros negativo  - tn: {matriz_confusão[0,0]}')\n",
    "    print(f'Recall: {round(recall_score(target, previsao_do_modelo),2)}')\n",
    "    print(f'F1-score: {round(f1_score(target, previsao_do_modelo),2)}')\n",
    "    print(f'Precisão: {round(precision_score(target, previsao_do_modelo), 2)}')\n",
    "    print(f'Acurácia: {round(accuracy_score(target, previsao_do_modelo),2)}')\n",
    "    \n",
    "    print('---------------------------------------------')\n",
    "    \n",
    "    figura, eixo = plt.subplots(figsize=(6, 6))\n",
    "    eixo.matshow(matriz_confusão, cmap=plt.cm.Greens)\n",
    "    for i in range(matriz_confusão.shape[0]):\n",
    "        for j in range(matriz_confusão.shape[1]):\n",
    "            eixo.text(x=j, y=i,s=matriz_confusão[i, j], va='center', ha='center', size='xx-large')\n",
    " \n",
    "    plt.xlabel('Predição', fontsize=15)\n",
    "    plt.ylabel('Real', fontsize=15)\n",
    "    plt.title('Matriz de Confusão', fontsize=18)\n",
    "    plt.savefig(nome_mtz, dpi = 300)\n",
    "    \n",
    "    \n",
    "    print('---------------------------------------------')\n",
    "    \n",
    "    #taxa_fp, taxa_vp, limiar = roc_curve(target, previsao_do_modelo)\n",
    "    taxa_fp, taxa_vp, limiar = roc_curve(target, proba[:])\n",
    "    auc = roc_auc_score(target, proba[:])\n",
    "    \n",
    "    \n",
    "    figure = plt.figure(figsize = (6, 6))\n",
    "    plt.plot(taxa_fp, taxa_vp, linewidth = 2, label='AUC = %0.2f' % auc)\n",
    "    plt.title('Curva ROC')\n",
    "    plt.plot([0, 1], [0, 1],'k--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('Taxa de verdadeiro positivo')\n",
    "    plt.xlabel('Taxa de falso positivo ')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(nome_fig, dpi = 300)\n",
    "    \n",
    "    return figura, figure\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grafico(x, y):\n",
    "    grafico = plt.plot(x, y)\n",
    "    return grafico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Importando as bibliotecas utilizadas na tarefa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM:\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo a função que criará o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelo_SVM(C, kernel, gamma, vetor_caracteristica_treinamento, rotulo_treinamento, vetor_caracteristica_teste):\n",
    "    model = SVC(C = C, kernel= kernel, gamma= gamma, probability=True) \n",
    "    model.fit(vetor_caracteristica_treinamento, rotulo_treinamento)\n",
    "    predicted= model.predict(vetor_caracteristica_teste)\n",
    "    return predicted, model.predict_proba(vetor_caracteristica_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizando o GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importando as bibliotecas utilizadas na tarefa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_grid(x_treinamento, x_teste, y_treinamento, y_teste):\n",
    "    # Definindo os parâmetros:\n",
    "    parametros_grid = {'C':  [0.1,1, 10, 100], \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel': ['rbf', 'poly', 'linear', 'sigmoid']} \n",
    "    # Criando o modelo em que a grade de parâmetros será testada:\n",
    "    grid = GridSearchCV(SVC(probability = True), parametros_grid, refit = True, verbose = 0)\n",
    "    # Treinando o modelo:\n",
    "    grid.fit(x_treinamento, y_treinamento)\n",
    "    # Imprimindo os melhores parâmetros:\n",
    "    print('Melhores parâmetros')\n",
    "    print(grid.best_params_)\n",
    "    # Imprimindo as configurações do melhor estimador:\n",
    "    print('Melhor estimador')\n",
    "    print(grid.best_estimator_)\n",
    "    # Realizando as predições:\n",
    "    grid_predictions = grid.predict(x_teste)\n",
    "    \n",
    "    print('---------------------------------------------')\n",
    "    \n",
    "    # Imprimindo as métricas de avaliação:\n",
    "    print(classification_report(y_teste, grid_predictions))\n",
    "    \n",
    "    print('---------------------------------------------')\n",
    "    \n",
    " \n",
    "    relatorio(grid_predictions, y_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando as bibliotecas utilizadas na tarefa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo as funções responsáveis por executar a tarefa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modificando a entrada para o formato exigido pela camada 'LSTM' do Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modificar_formato_entrada(indicadores):\n",
    "    # Arrumando a entrada do conjunto de treinamento no formato exigido pelo LSTM\n",
    "    x = indicadores\n",
    "    x = x.reshape((x.shape[0],x.shape[1],1))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definindo os modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(xtreino_novo):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, activation= 'relu', input_shape = (xtreino_novo.shape[1],xtreino_novo.shape[2])))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm1(indicadores_treinamento, indicadores_teste, target_treinamento, target_teste):\n",
    "    \n",
    "    startTime = time.time()\n",
    "    \n",
    "    # Arrumando a entrada dos conjuntos de treinamento e teste no formato exigido pelo LSTM\n",
    "    xtreino_novo = modificar_formato_entrada(indicadores_treinamento)\n",
    "    xteste_novo = modificar_formato_entrada(indicadores_teste)\n",
    "    \n",
    "    # Modelo 1:\n",
    "    model = create_model(xtreino_novo)\n",
    "\n",
    "    # Resumo da Rede Neural:\n",
    "    print('Resumo da Rede Neural:')\n",
    "    model.summary()\n",
    "    print('---------------------------------------------')\n",
    "    \n",
    "    # Ajuste da Rede Neural ao conjunto de treinamento:\n",
    "    model.fit(xtreino_novo, target_treinamento, epochs = 10, batch_size = 1)\n",
    "    executionTime = (time.time() - startTime)\n",
    "    print('Tempo de Execução: ' + str(executionTime))\n",
    "    \n",
    "    # Ajustando o modelo ao conjunto de entrada de teste: \n",
    "    y_predict = model.predict_classes(xteste_novo)\n",
    "    \n",
    "    return y_predict, model.predict_proba(xteste_novo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model2(xtreino_novo):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=50, activation='relu', return_sequences=True, input_shape=(xtreino_novo.shape[1],xtreino_novo.shape[2])))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=50, activation='relu', return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm2(indicadores_treinamento, indicadores_teste, target_treinamento, target_teste):\n",
    "    \n",
    "    \n",
    "    startTime = time.time()\n",
    "    \n",
    "    # Arrumando a entrada dos conjuntos de treinamento e teste no formato exigido pelo LSTM\n",
    "    xtreino_novo = modificar_formato_entrada(indicadores_treinamento)\n",
    "    xteste_novo = modificar_formato_entrada(indicadores_teste)\n",
    "    \n",
    "    # Modelo 2:\n",
    "    model = create_model2(xtreino_novo)\n",
    "\n",
    "    # Resumo da Rede Neural:\n",
    "    print('Resumo da Rede Neural:')\n",
    "    model.summary()\n",
    "    print('---------------------------------------------')\n",
    "    \n",
    "    # Ajuste da Rede Neural ao conjunto de treinamento:\n",
    "    model.fit(xtreino_novo, target_treinamento, batch_size=64, epochs=170)\n",
    "    executionTime = (time.time() - startTime)\n",
    "    print('Tempo de Execução: ' + str(executionTime))\n",
    "    \n",
    "    # Ajustando o modelo ao conjunto de entrada de teste: \n",
    "    y_predict = model.predict_classes(xteste_novo)\n",
    "    \n",
    "    return y_predict, model.predict_proba(xteste_novo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model3(xtreino_novo):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(12, activation='relu', return_sequences = True, input_shape = (xtreino_novo.shape[1],xtreino_novo.shape[2])))\n",
    "    model.add(LSTM(8, activation='relu'))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm3(indicadores_treinamento, indicadores_teste, target_treinamento, target_teste):\n",
    "    \n",
    "    \n",
    "    startTime = time.time()\n",
    "    \n",
    "    # Arrumando a entrada dos conjuntos de treinamento e teste no formato exigido pelo LSTM\n",
    "    xtreino_novo = modificar_formato_entrada(indicadores_treinamento)\n",
    "    xteste_novo = modificar_formato_entrada(indicadores_teste)\n",
    "    \n",
    "    # Modelo 3:\n",
    "    model = create_model3(xtreino_novo)\n",
    "\n",
    "    # Resumo da Rede Neural:\n",
    "    print('Resumo da Rede Neural:')\n",
    "    model.summary()\n",
    "    print('---------------------------------------------')\n",
    "    \n",
    "    # Ajuste da Rede Neural ao conjunto de treinamento:\n",
    "    model.fit(xtreino_novo, target_treinamento, epochs = 10, batch_size = 1)\n",
    "    executionTime = (time.time() - startTime)\n",
    "    print('Tempo de Execução: ' + str(executionTime))\n",
    "    \n",
    "    # Ajustando o modelo ao conjunto de entrada de teste: \n",
    "    y_predict = model.predict_classes(xteste_novo)\n",
    "    \n",
    "    return y_predict, model.predict_proba(xteste_novo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model4(xtreino_novo):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(30, activation= 'relu', input_shape = (xtreino_novo.shape[1],xtreino_novo.shape[2])))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm4(indicadores_treinamento, indicadores_teste, target_treinamento, target_teste):\n",
    "    \n",
    "    startTime = time.time()\n",
    "    \n",
    "    # Arrumando a entrada dos conjuntos de treinamento e teste no formato exigido pelo LSTM\n",
    "    xtreino_novo = modificar_formato_entrada(indicadores_treinamento)\n",
    "    xteste_novo = modificar_formato_entrada(indicadores_teste)\n",
    "    \n",
    "    # Modelo 4:\n",
    "    model = create_model4(xtreino_novo)\n",
    "\n",
    "    # Resumo da Rede Neural:\n",
    "    print('Resumo da Rede Neural:')\n",
    "    model.summary()\n",
    "    print('---------------------------------------------')\n",
    "    \n",
    "    # Ajuste da Rede Neural ao conjunto de treinamento:\n",
    "    model.fit(xtreino_novo, target_treinamento, epochs = 10, batch_size = 1)\n",
    "    executionTime = (time.time() - startTime)\n",
    "    print('Tempo de Execução: ' + str(executionTime))\n",
    "    \n",
    "    # Ajustando o modelo ao conjunto de entrada de teste: \n",
    "    y_predict = model.predict_classes(xteste_novo)\n",
    "    return y_predict, model.predict_proba(xteste_novo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
